{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd #dataframes e series\n",
    "import matplotlib.pyplot as plt #graphics\n",
    "import numpy as np #matrixes\n",
    "import csv #read files\n",
    "import nltk #Tokenize\n",
    "import re #RegEx\n",
    "import string \n",
    "import collections\n",
    "import scipy #Sparse Matrixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer #tf-idf; tf\n",
    "from sklearn.naive_bayes import MultinomialNB #Naïve Bayes\n",
    "from sklearn import metrics #Evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import multiprocessing\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (20,10)\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable = pd.read_csv('C:/Users/sergiojesus/Desktop/Recursos/comments_toxicos/Dados/train.csv')\n",
    "Testtable = pd.read_csv('C:/Users/sergiojesus/Desktop/Recursos/comments_toxicos/Dados/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingcomments = Trainingtable.comment_text\n",
    "Testcomments = Testtable.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_rows = Trainingtable.shape[0] #Número de linhas\n",
    "num_missing = num_rows - Trainingtable.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Trainingtable.comment_text.value_counts(dropna=False)) # Print da ocorrência de valores numa dada coluna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subset = Trainingtable.iloc[[42, 44], [3]]\n",
    "subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable.groupby('toxic').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "   Para qualquer feature, P(toxic|feature = true) = 93%, excepto P(toxic|severe_toxic = true) = 100 %  \n",
    "   P(toxic)= 9,5844%  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['f_sum']= (summ) #adicionar nova coluna à tabela de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(Trainingtable['sum'], bins = 6)\n",
    "plt.show() #histograma da soma de características negativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['sum'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summ6 = summ[summ == 6]\n",
    "for i in summ6.index:\n",
    "    print(Trainingtable['comment_text'][i])  #Print dos comentários que infringem todas as  para ver padrões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "comments = Trainingtable['comment_text'] #Criação de uma pandas.Series dos comentários\n",
    "uppercasecount = pd.Series() #Criação do contador em forma de pandas.Series\n",
    "for i in range(comments.shape[0]): \n",
    "    comment = comments[i]\n",
    "    count = 0\n",
    "    for c in comment:\n",
    "        if c.isupper():\n",
    "            count += 1 #Programado intuitivamente, não tem compreensão de listas\n",
    "    uppercasecount = uppercasecount.append(pd.Series([count], index = [i])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['uppercase_count'] = uppercasecount #Inserir o número de maiúsculas por comentário na tabela de treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable[['sum','uppercase_count']].groupby('sum').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('C:/Users/sergiojesus/Desktop/Recursos/comments_toxicos/full-list-of-bad-words-banned-by-google.csv') as f:\n",
    "  reader = csv.reader(f)\n",
    "  swearsBoW = list(reader)\n",
    "for i in range(1,len(swearsBoW)):\n",
    "    for word in swearsBoW[i]:\n",
    "            swearsBoW[0].append(word)\n",
    "swearsBoW = swearsBoW[0]\n",
    "newlist= list()\n",
    "for word in swearsBoW:\n",
    "    newword = word.strip()\n",
    "    newword2 = newword.lower()\n",
    "    newlist.append(newword2)\n",
    "swearsBoW = newlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swear_count = pd.Series()\n",
    "wordlist = [comment.split() for comment in comments]\n",
    "commentcount = 0\n",
    "for sentence in wordlist:\n",
    "    count = 0\n",
    "    for word in sentence:\n",
    "        lowerword = word.lower()\n",
    "        if lowerword in swearsBoW:\n",
    "            count += 1\n",
    "    swear_count = swear_count.append(pd.Series([count], index = [commentcount]))\n",
    "    commentcount += 1\n",
    "    f.value = commentcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['swear_count'] = swear_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable[['sum','swear_count']].groupby('sum').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['uppercase_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tentativa de criação de um Bag of Words para os comentários todos\n",
    "#Sem compreensão de listas por enquanto\n",
    "BagofWords = dict() \n",
    "commentcount = 0\n",
    "for comment in wordlist:\n",
    "    for word in comment:\n",
    "        BagofWords[word.lower()] = 0\n",
    "    commentcount += 1\n",
    "    f.value = commentcount/2\n",
    "for comment in wordlist:\n",
    "    for word in comment:\n",
    "        BagofWords[word.lower()] += 1\n",
    "    commentcount += 1\n",
    "    f.value = commentcount/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BagofWords #ainda tem pontuação, palavras com 1 char, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('C:/Users/sergiojesus/Desktop/Recursos/comments_toxicos/full-list-of-bad-words-banned-by-google.csv') as f:\n",
    "  reader = csv.reader(f)\n",
    "  swearsBoW1 = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swearsBoW1 = [nltk.word_tokenize(a) for a in swearsBoW]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CommentTokens = [nltk.word_tokenize(a) for a in comments]\n",
    "CommentTokens = [item for sublist in CommentTokens for item in sublist] #itertools.chain para o mesmo resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swearsTokens = [a for b in swearsBoW1 for a in b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = Trainingtable.comment_text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(lens)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "swear = list()\n",
    "for i in Trainingtable.swear_count:\n",
    "    if i > 0:\n",
    "        swear.append(1)\n",
    "    else:\n",
    "        swear.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['swear'] = swear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Trainingtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "print(type(re_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "tokenize(Trainingtable['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Naïve Bayes* \n",
    "##### (com imput = freq de token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Countmodel = CountVectorizer(max_df= 0.8 , min_df= 2, tokenizer = nltk.word_tokenize, ngram_range= (1,3))\n",
    "Counttraining = Countmodel.fit_transform(Trainingtable['comment_text'])\n",
    "CountTest = Countmodel.transform(Testtable['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segundo a página da library SKLEARN, o MNB é usado com *features* discretas, mas teoricamente pode-se usar variáveis continuas.\n",
    "\n",
    "O melhor resultado foi obtido com o imput de frequência de tokens e com tri-grams e com P(class == True), ou seja com o método predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "Prediction = pd.DataFrame()\n",
    "preds = np.zeros((len(Testtable), len(label_cols)))\n",
    "for i,j in enumerate(label_cols):\n",
    "    classifier.fit(Counttraining, Trainingtable[j])\n",
    "    preds[:,i] = classifier.predict_proba(CountTest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = pd.DataFrame(Testtable['id'])\n",
    "Prediction = pd.concat([Prediction, pd.DataFrame(preds, columns = label_cols)], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Suport Vector Machines*\n",
    "##### (com imput = TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tfmodel = TfidfVectorizer(max_df= 0.8 , min_df= 2, tokenizer = nltk.word_tokenize, ngram_range= (1,3), max_features = 100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tfidftraining = Tfmodel.fit_transform(Trainingtable['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tfidftest = Tfmodel.transform(Testtable['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierSVM = svm.SVC()\n",
    "predsSVM = np.zeros((len(Testtable), len(label_cols)))\n",
    "for i,j in enumerate(label_cols):\n",
    "    print(j)\n",
    "    classifierSVM.fit(Tfidftraining, Trainingtable[j])\n",
    "    predsSVM[:,i] = classifier.predict_proba(Tfidftest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierSVM = svm.SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Logistic Regression* \n",
    "##### (com imput = freq de token) (AUC em Crossfold Validation mais alto que TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logisticmodel = LogisticRegression(C=4, dual=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergiojesus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\base.py:340: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(prob, prob)\n"
     ]
    }
   ],
   "source": [
    "Prediction = pd.DataFrame()\n",
    "preds = np.zeros((len(Testtable), len(label_cols)))\n",
    "for i,j in enumerate(label_cols):\n",
    "    logisticmodel.fit(Counttraining, Trainingtable[j])\n",
    "    preds[:,i] = logisticmodel.predict_proba(CountTest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = pd.DataFrame(Testtable['id'])\n",
    "Prediction = pd.concat([Prediction, pd.DataFrame(preds, columns = label_cols)], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>3.586194e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.001265</td>\n",
       "      <td>5.611316e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.000523</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>1.556571e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>4.572448e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>3.118968e-04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  1.000000      0.000297  1.000000  0.000387  0.999949   \n",
       "1  0000247867823ef7  0.000467      0.000295  0.000635  0.000006  0.001265   \n",
       "2  00013b17ad220c46  0.006838      0.000523  0.002328  0.000018  0.000531   \n",
       "3  00017563c3f7919a  0.000002      0.000004  0.000003  0.000002  0.000016   \n",
       "4  00017695ad8997eb  0.009227      0.000882  0.002763  0.000310  0.003582   \n",
       "\n",
       "   identity_hate  \n",
       "0   3.586194e-01  \n",
       "1   5.611316e-04  \n",
       "2   1.556571e-04  \n",
       "3   4.572448e-07  \n",
       "4   3.118968e-04  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = pd.DataFrame()\n",
    "preds = np.zeros((len(Testtable), len(label_cols)))\n",
    "for i,j in enumerate(label_cols):\n",
    "    logisticmodel.fit(Tfidftraining, Trainingtable[j])\n",
    "    preds[:,i] = logisticmodel.predict_proba(Tfidftest)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = pd.DataFrame(Testtable['id'])\n",
    "Prediction = pd.concat([Prediction, pd.DataFrame(preds, columns = label_cols)], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>0.999333</td>\n",
       "      <td>0.061647</td>\n",
       "      <td>0.997785</td>\n",
       "      <td>0.038995</td>\n",
       "      <td>0.914696</td>\n",
       "      <td>0.342033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>0.005680</td>\n",
       "      <td>0.002760</td>\n",
       "      <td>0.003503</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.003531</td>\n",
       "      <td>0.002257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>0.016632</td>\n",
       "      <td>0.003045</td>\n",
       "      <td>0.007514</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.001380</td>\n",
       "      <td>0.000782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>0.002620</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000910</td>\n",
       "      <td>0.002312</td>\n",
       "      <td>0.000665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>0.016137</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.005803</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.005920</td>\n",
       "      <td>0.000923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     toxic  severe_toxic   obscene    threat    insult  \\\n",
       "0  00001cee341fdb12  0.999333      0.061647  0.997785  0.038995  0.914696   \n",
       "1  0000247867823ef7  0.005680      0.002760  0.003503  0.000262  0.003531   \n",
       "2  00013b17ad220c46  0.016632      0.003045  0.007514  0.000185  0.001380   \n",
       "3  00017563c3f7919a  0.002620      0.001808  0.001613  0.000910  0.002312   \n",
       "4  00017695ad8997eb  0.016137      0.001859  0.005803  0.001112  0.005920   \n",
       "\n",
       "   identity_hate  \n",
       "0       0.342033  \n",
       "1       0.002257  \n",
       "2       0.000782  \n",
       "3       0.000665  \n",
       "4       0.000923  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *NB+Logistic regression*\n",
    "##### (input = TF-IDF)\n",
    "Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tfmodel = TfidfVectorizer(max_df= 0.8 , min_df= 2, tokenizer = nltk.word_tokenize, ngram_range= (1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TrainingTFID = Tfmodel.fit_transform(Trainingcomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TestTFID = Tfmodel.transform(Testcomments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NBclf = MultinomialNB()\n",
    "NBclf.fit(TrainingTFID,Trainingtable.toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FeatSelectModel = SelectFromModel(NBclf, prefit= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewX = FeatSelectModel.transform(TrainingTFID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571, 1686832)\n",
      "(159571, 1353252)\n"
     ]
    }
   ],
   "source": [
    "print(TrainingTFID.shape)\n",
    "print(NewX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxic\n",
      "severe_toxic\n",
      "obscene\n",
      "threat\n",
      "insult\n",
      "identity_hate\n"
     ]
    }
   ],
   "source": [
    "NBclf = MultinomialNB()\n",
    "LogRes = LogisticRegression()\n",
    "preds = np.zeros((len(Testtable), len(label_cols)))\n",
    "for i,colname in enumerate(label_cols):\n",
    "    NBclf.fit(TrainingTFID,Trainingtable[colname])\n",
    "    FeatSelectModel = SelectFromModel(NBclf, prefit= True)\n",
    "    NewX = FeatSelectModel.transform(TrainingTFID)\n",
    "    NewTestX = FeatSelectModel.transform(TestTFID)\n",
    "    NBclf.fit(NewX,Trainingtable[colname])\n",
    "    LogResX = TestTFID.multiply(NBclf.predict_proba(NewTestX)[:,1].reshape(-1, 1))\n",
    "    LogEntryX = TrainingTFID.multiply(NBclf.predict_proba(NewX)[:,1].reshape(-1, 1))\n",
    "    LogRes.fit(LogEntryX,Trainingtable[colname])\n",
    "    preds[:,i] = LogRes.predict_proba(LogResX)[:,1]\n",
    "    print(colname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = pd.DataFrame(Testtable['id'])\n",
    "Prediction = pd.concat([Prediction, pd.DataFrame(preds, columns = label_cols)], axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction.to_csv('submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def toptokens(Tfidfmatrix, tokens, n=5):\n",
    "    npmatrix = Tfidfmatrix.toarray()\n",
    "    npmatrix[npmatrix == 0] = np.nan\n",
    "    npmeans = np.nanmean(npmatrix, axis = 0)\n",
    "    topids = np.argsort(npmeans)[::-1][:n]\n",
    "    toptoken = [(tokens[i], npmeans[i]) for i in topids]\n",
    "    df = pd.DataFrame(toptoken)\n",
    "    df.columns = ['feature', 'TF-IDF']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "toptokens(Tfidftraining5, Features, n = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Tfidftraining5.toarray().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summ1 = Trainingtable.toxic\n",
    "summ2 = Trainingtable.severe_toxic\n",
    " = list()\n",
    "for i in range(summ2.shape[0]):\n",
    "    summ4.append(str(summ2[i]) +','+ str(summ3[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(summ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(summ2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summ4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def join_class(row):\n",
    "    toxic = row['toxic']\n",
    "    severe_toxic = row['severe_toxic']\n",
    "    obscene = row['obscene']\n",
    "    threat = row['threat']\n",
    "    insult = row['insult']\n",
    "    identity_hate = row['identity_hate']\n",
    "    jclass = str(toxic) + str(severe_toxic) + str(obscene) + str(threat) + str(insult) + str(identity_hate)\n",
    "    return jclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable=Trainingtable.assign(Classes_str = Trainingtable.apply(join_class, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "Trainingtable.groupby('Classes_str').agg('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable = Trainingtable.assign(comment_value = Trainingtable.apply(average_score, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_score(row):\n",
    "    return Tfidftraining[row.name,:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Tfidftraining[5,:].toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = Trainingtable.iloc[65738]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Trainingtable['comment_value'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortedTT = Trainingtable.sort_values('comment_value', ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortedTT.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes = pd.unique(Trainingtable.Classes_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numelement = 0\n",
    "commentid_list = list()\n",
    "for element in list_classes:\n",
    "    commentid_list_sec = list()\n",
    "    commentid_list_sec.append(sortedTT[sortedTT['Classes_str'] == element].index.values)\n",
    "    numelement +=1\n",
    "    commentid_list.append(commentid_list_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(commentid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sortedTT[sortedTT['Classes_str'] == '000000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = 0 \n",
    "for i in commentid_list:\n",
    "    for j in i:\n",
    "        (j[:20])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "help(Int64Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "commentid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for row in Prediction:\n",
    "    print(row) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction2 = pd.DataFrame(0, index = np.arange(len(Prediction)), columns = label_cols3)\n",
    "Prediction2['id'] = Prediction['id']\n",
    "Prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_cols3 = ['id','toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Tfidftraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CBTW1(ntf, A, B, C, D):\n",
    "    return ntf * log(1+(A/B)*(A/C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Randomcomment = Trainingtable.iloc[2,1]\n",
    "print(type(Randomcomment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(word_tokenize(Randomcomment))\n",
    "Randomcomment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = ntf_matrix(Tftraining)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "f = FloatProgress(min=0, max=621305)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tf = TfidfVectorizer(max_df= 0.8 , min_df= 2, tokenizer = nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ntftraining = Tf.fit_transform(Trainingtable['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = Tftraining.getrow(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Tftraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(Tftraining.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "COMMENT = 'comment_text'\n",
    "Trainingtable[COMMENT].fillna(\"unknown\", inplace=True)\n",
    "Testtable[COMMENT].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(classifier.predict_proba(CountTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.spy(Counttraining)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counttraining.nnz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counttraining.shape[0]*Counttraining.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Counttraining.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "24413307/269169469072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scipy.linalg.expm_cond(Counttraining)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *CBTW(1)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def maxvec(matrix):\n",
    "    vec = list()\n",
    "    for i in range(matrix.shape[0]):\n",
    "        vec.append(matrix.getrow(i).max())\n",
    "        f.value = i\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valuevec = maxvec(Counttraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b637a3da734fb59dd15795a6fe51ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = FloatProgress(min=0, max=159571)\n",
    "display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergiojesus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py:774: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive. lil_matrix is more efficient.\n",
      "  SparseEfficiencyWarning)\n",
      "C:\\Users\\sergiojesus\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py:470: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return self.astype(np.float_)._mul_scalar(1./other)\n"
     ]
    }
   ],
   "source": [
    "ntftraining = scipy.sparse.csr_matrix((Counttraining.shape[0],Counttraining.shape[1]))\n",
    "f.value = 0\n",
    "for i in range(Counttraining.shape[0]):\n",
    "    f.value = i\n",
    "    ntftraining[i,:] = Counttraining.getrow(i) / valuevec[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "0-dimensional array given. Array must be at least two-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-efaa3ce58f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcond\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCounttraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36mcond\u001b[1;34m(x, p)\u001b[0m\n\u001b[0;32m   1484\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# in case we have a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1485\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1486\u001b[1;33m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_uv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1487\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36msvd\u001b[1;34m(a, full_matrices, compute_uv)\u001b[0m\n\u001b[0;32m   1367\u001b[0m     \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_makearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1368\u001b[0m     \u001b[0m_assertNoEmpty2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1369\u001b[1;33m     \u001b[0m_assertRankAtLeast2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1370\u001b[0m     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_commonType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\linalg\\linalg.py\u001b[0m in \u001b[0;36m_assertRankAtLeast2\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m             raise LinAlgError('%d-dimensional array given. Array must be '\n\u001b[1;32m--> 202\u001b[1;33m                     'at least two-dimensional' % a.ndim)\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_assertSquareness\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLinAlgError\u001b[0m: 0-dimensional array given. Array must be at least two-dimensional"
     ]
    }
   ],
   "source": [
    "np.linalg.cond(Counttraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<159571x1686832 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 24413307 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counttraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 33877)\t0.333333333333\n",
      "  (0, 35489)\t0.333333333333\n",
      "  (0, 68629)\t0.333333333333\n",
      "  (0, 87454)\t0.333333333333\n",
      "  (0, 116258)\t0.333333333333\n",
      "  (0, 116439)\t0.333333333333\n",
      "  (0, 183272)\t0.333333333333\n",
      "  (0, 188069)\t0.333333333333\n",
      "  (0, 188093)\t0.333333333333\n",
      "  (0, 257126)\t0.333333333333\n",
      "  (0, 257577)\t0.333333333333\n",
      "  (0, 257630)\t0.333333333333\n",
      "  (0, 289184)\t0.333333333333\n",
      "  (0, 308051)\t0.333333333333\n",
      "  (0, 308066)\t0.333333333333\n",
      "  (0, 370380)\t0.333333333333\n",
      "  (0, 372366)\t0.333333333333\n",
      "  (0, 372367)\t0.333333333333\n",
      "  (0, 486636)\t0.333333333333\n",
      "  (0, 486652)\t0.333333333333\n",
      "  (0, 564807)\t0.333333333333\n",
      "  (0, 566162)\t0.333333333333\n",
      "  (0, 566548)\t0.333333333333\n",
      "  (0, 571960)\t0.333333333333\n",
      "  (0, 589064)\t0.333333333333\n",
      "  :\t:\n",
      "  (159570, 1197901)\t0.333333333333\n",
      "  (159570, 1198394)\t0.333333333333\n",
      "  (159570, 1198410)\t0.333333333333\n",
      "  (159570, 1230677)\t0.333333333333\n",
      "  (159570, 1232203)\t0.333333333333\n",
      "  (159570, 1232572)\t0.333333333333\n",
      "  (159570, 1232574)\t0.333333333333\n",
      "  (159570, 1440515)\t0.333333333333\n",
      "  (159570, 1440517)\t0.333333333333\n",
      "  (159570, 1454267)\t0.333333333333\n",
      "  (159570, 1456002)\t0.333333333333\n",
      "  (159570, 1456057)\t0.333333333333\n",
      "  (159570, 1529436)\t0.333333333333\n",
      "  (159570, 1529476)\t0.333333333333\n",
      "  (159570, 1529496)\t0.333333333333\n",
      "  (159570, 1568160)\t0.333333333333\n",
      "  (159570, 1569726)\t0.333333333333\n",
      "  (159570, 1591003)\t0.333333333333\n",
      "  (159570, 1592741)\t0.333333333333\n",
      "  (159570, 1592742)\t0.333333333333\n",
      "  (159570, 1651925)\t0.666666666667\n",
      "  (159570, 1659974)\t0.333333333333\n",
      "  (159570, 1660033)\t0.333333333333\n",
      "  (159570, 1667199)\t0.333333333333\n",
      "  (159570, 1667201)\t0.333333333333\n"
     ]
    }
   ],
   "source": [
    "print(ntftraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 761887)\t1\n",
      "  (0, 1282139)\t1\n",
      "  (0, 1120020)\t1\n",
      "  (0, 1349495)\t1\n",
      "  (0, 1428126)\t1\n",
      "  (0, 671735)\t1\n",
      "  (0, 1354440)\t1\n",
      "  (0, 1428468)\t1\n",
      "  (0, 1215613)\t1\n",
      "  (0, 987726)\t1\n",
      "  (0, 566548)\t1\n",
      "  (0, 1147651)\t1\n",
      "  (0, 308066)\t1\n",
      "  (0, 116439)\t1\n",
      "  (0, 623575)\t1\n",
      "  (0, 372367)\t1\n",
      "  (0, 257630)\t1\n",
      "  (0, 989006)\t1\n",
      "  (0, 1452182)\t1\n",
      "  (0, 188093)\t1\n",
      "  (0, 1228363)\t1\n",
      "  (0, 1589659)\t1\n",
      "  (0, 711037)\t1\n",
      "  (0, 1528802)\t1\n",
      "  (0, 589849)\t1\n",
      "  :\t:\n",
      "  (159570, 138178)\t1\n",
      "  (159570, 140931)\t1\n",
      "  (159570, 689690)\t1\n",
      "  (159570, 1568160)\t1\n",
      "  (159570, 1591003)\t1\n",
      "  (159570, 1659974)\t1\n",
      "  (159570, 123392)\t1\n",
      "  (159570, 8823)\t1\n",
      "  (159570, 191534)\t1\n",
      "  (159570, 716556)\t1\n",
      "  (159570, 1651925)\t2\n",
      "  (159570, 1454267)\t1\n",
      "  (159570, 8739)\t3\n",
      "  (159570, 191523)\t3\n",
      "  (159570, 815758)\t1\n",
      "  (159570, 1037557)\t2\n",
      "  (159570, 815598)\t1\n",
      "  (159570, 1197901)\t1\n",
      "  (159570, 566162)\t1\n",
      "  (159570, 564807)\t1\n",
      "  (159570, 289184)\t2\n",
      "  (159570, 760943)\t2\n",
      "  (159570, 68629)\t1\n",
      "  (159570, 982937)\t1\n",
      "  (159570, 975433)\t1\n"
     ]
    }
   ],
   "source": [
    "print(Counttraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
